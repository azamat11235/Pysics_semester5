{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Большое практическое задание 1\n",
    "# Классификация изображений цифр метрическими методами\n",
    "\n",
    "## курс \"Машинное обучение 1\", программа OzonMasters, 2021\n",
    "\n",
    "## Студент: Султонов Азамат"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "\n",
    "Данное задание направлено на ознакомление с метрическими алгоритмами классификации, а также методами работы с изображениями. В задании вам будет необходимо:\n",
    "\n",
    "1. Написать на языке Python собственные реализации метода ближайших соседей и кросс-валидации. Реализации должны соответствовать спецификации, описанной в прилагающихся модулях.     \n",
    "    Частично проверить правильность выполнения своих реализаций можно с помощью системы ejudge в соответствующем соревновании.\n",
    "    **Внимание.** Прохождение всех тестов в соревновании не гарантирует правильность решения.\n",
    "\n",
    "\n",
    "2. Провести описанные ниже эксперименты с датасетом изображений цифр MNIST, описать полученые результаты и ответить на предложенные вопросы.\n",
    "\n",
    "\n",
    "3. Подготовить отчёт о проделанной работе. Удалите черновые выводы, оставьте только тот код, который является ответом к пунктам задания. Сохраните ноутбук в форматах .ipynb и .html одновременно.\n",
    "\n",
    "    **Замечание.** Чтобы экспорировать jupyter notebook в .html нужно выбрать:\n",
    "    `File -> Download as -> HTML (.html).`\n",
    "    Для экспорта notebook в .html в Google Colab, воспользуйтесь [следующим кодом](https://gist.github.com/vbugaevskii/b9c6181f2ad83e11f5b9c92d315cb2de).\n",
    "Большая просьба: подписывайте свой отчет (в названии файла и внутри ноутбука).\n",
    "\n",
    "\n",
    "4. В систему проверки необходимо сдать отчёт в обоих форматах и .zip архив с написанными модулями.\n",
    "\n",
    "    Большая просьба: jupyter notebook и html файл не запаковывать в архив, а сдавать отдельно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Некоторые полезные советы\n",
    "\n",
    "1. Для того, чтобы не перезагружать jupyter notebook каждый раз после того, как вы внесли изменения в модуль `knn`, можно добавить ячейку с таким содержимым:\n",
    "     \n",
    "```\n",
    "    %load_ext autoreload\n",
    "    \n",
    "    %autoreload 2\n",
    "```\n",
    "   \n",
    "2. Не нужно копировать свой код из модулей в jupyter notebook, пользуйтесь им, как если бы это была библиотека. Для этого поместите директорию `knn` рядом с notebook-ом. Пример, как может выглядеть содержимое вашей рабочей директории:\n",
    "\n",
    "```\n",
    "    tree\n",
    "    ---knn\n",
    "    ------__init__.py\n",
    "    ------classification.py\n",
    "    ------distances.py\n",
    "    ------model_selection.py\n",
    "    ------nearest_neighbors.py\n",
    "    ---tests\n",
    "    ------__init__.py\n",
    "    ------test_classification.py\n",
    "    ------test_distances.py\n",
    "    ------test_model_selection.py\n",
    "    ------test_nearest_neigbours.py\n",
    "    experiments.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реализация алгоритмов (10 баллов)\n",
    "\n",
    "Прототипы функций должны строго соответствовать прототипам, описанным в спецификации и проходить\n",
    "все выданные тесты. Задание, не проходящее все выданные тесты, приравнивается к невыполненному. При\n",
    "написании **необходимо пользоваться** стандартными средствами языка Python и библиотекой numpy. Библиотеками scipy и scikit-learn пользоваться **запрещено**, если это не обговорено отдельно в пункте задания. Для\n",
    "экспериментов в бонусной части разрешается пользоваться любыми открытыми библиотеками, реализующими\n",
    "алгоритмы обработки изображений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среди предоставленных файлов должны быть следующие модули и функции в них\n",
    "\n",
    "1. Модуль `knn.distances` с реализацией функции для вычисления расстояния:\n",
    "    1. `euclidean_distance(X, Y)` — реализация евклидова расстояния с заданными свойствами;\n",
    "    2. `cosine_distance(X, Y)` — реализация косинусного расстояния с заданными свойствами;\n",
    "\n",
    "\n",
    "2. Модуль `knn.nearest_neighbors`, содержащий собственную реализацию поиска ближайших соседей.\n",
    "    \n",
    "    Класс `NearestNeighborsFinder` с методами:\n",
    "      1. `__init__(self, n_neighbors, metric=\"euclidean\")` — конструктор (инициализатор) класса;\n",
    "      2. `fit(self, X, y=None)` — обучение алгоритма;\n",
    "      3. `kneighbors(self, X, return_distance=False)` — поиск ближайших соседей.\n",
    "\n",
    "\n",
    "3. Модуль `knn.classification`, содержащий собственную реализацию классификатора на основе метода ближайших соседей.\n",
    "\n",
    "    Класс `KNNClassifier` с методами:\n",
    "    \n",
    "    1. `__init__(self, n_neighbors, algorithm=’my_own’, metric=’euclidean’, weights=’uniform’)` — конструктор (инициализатор) класса;\n",
    "    2. `fit(self, X, y=None)` — обучение алгоритма;\n",
    "    3. `kneighbors(self, X, return_distance=False)` — поиск ближайших соседей;\n",
    "    4. `predict(self, X)` — редсказание на новых данных;\n",
    "    5. `_predict_precomputed(self, indices, distances)` — вспомогательный метод.\n",
    "    \n",
    "   Класс `BatchedKNNClassifier`, полезный для работы с большими выборками, с методами:\n",
    "   \n",
    "    1. `__init__(self, n_neighbors, algorithm=’my_own’, metric=’euclidean’, weights=’uniform’, batch_size=None)` — конструктор (инициализатор) класса\n",
    "    2. `kneighbors(self, X, return_distance=False)` — поиск ближайших соседей, разбитый на несколько итераций по батчам\n",
    "    3. `set_batch_size(self, batch_size)` — метод для выставления нового значения размера батча\n",
    "\n",
    "\n",
    "4. Модуль `knn.model_selection` с реализациями функций для применения кросс-валидации:\n",
    "\n",
    "    1. `knn_cross_val_score(X, y, k_list, scoring, cv=None, **kwargs)` — функция для измерения качества на кросс-валидации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ожидается, что реализациия всех классов и функций будет максимально эффективной. Дополнительно вам предоставлены открытые unit-тесты, которые находятся рядом с модулем `knn` в директории `tests` Чтобы запустить тесты в консоли требуется выполнить одну из команд:\n",
    "\n",
    "\n",
    "```\n",
    "$ python -m unittest                            # запуск всех тестов\n",
    "$ python -m unittest tests/test_distances.py    # запуск конкретных тестов\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Эксперименты (15 баллов)\n",
    "\n",
    "Здесь вы можете заимпортировать всё, что вам потребуется для экспериментов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from knn.distances import euclidean_distance, cosine_distance \n",
    "from knn.classification import BatchedKNNClassifier\n",
    "from knn.model_selection import knn_cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка даннных\n",
    "\n",
    "Эксперименты этого задания необходимо проводить на датасете MNIST. Загрузить датасет можно при помощи функции `sklearn.datasets.fetch_openml(\"mnist_784\")` или скачать вручную с сайта\n",
    "http://yann.lecun.com/exdb/mnist/. Датасет необходимо разбить на обучающую выборку (первые 60 тыс.\n",
    "объектов) и тестовую выборку (10 тыс. последних объектов)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = datasets.fetch_openml('mnist_784', version=1, cache=True, return_X_y=True)\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy(dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:6000]\n",
    "y_train = y[:6000]\n",
    "X_test = X[6000:]\n",
    "y_test = y[6000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Исследование скорости методов поиска (4 балла)\n",
    "\n",
    "Исследуйте, какой алгоритм поиска ближайших соседей будет быстрее работать в различных ситуациях.\n",
    "\n",
    "Измерьте для каждого алгоритма поиска (`kd_tree`, `ball_tree`, `brute` и `my_own`) время нахождения 5 ближайших соседей для каждого объекта тестовой выборки по евклидовой метрике. Выберите подмножество признаков, по которому будет считаться расстояние, размера 10, 20, 100 (подмножество признаков выбирается один раз для всех объектов, случайно).\n",
    "\n",
    "**Замечание.** Для оценки времени долго работающих функций можно пользоваться либо функциями из\n",
    "модуля time, либо magic-командой %time, которая запускает код лишь один раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ________________________________________\n",
      "|algorithm| kd_tree\n",
      "|_________|______________________________\n",
      "number of features: 10\n",
      "922 µs ± 305 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n",
      "number of features: 20\n",
      "1.54 ms ± 436 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n",
      "number of features: 100\n",
      "12.5 ms ± 290 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "----------\n",
      " ________________________________________\n",
      "|algorithm| ball_tree\n",
      "|_________|______________________________\n",
      "number of features: 10\n",
      "681 µs ± 172 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n",
      "number of features: 20\n",
      "1.03 ms ± 269 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n",
      "number of features: 100\n",
      "12.5 ms ± 3.26 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "----------\n",
      " ________________________________________\n",
      "|algorithm| brute\n",
      "|_________|______________________________\n",
      "number of features: 10\n",
      "346 µs ± 73 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n",
      "number of features: 20\n",
      "621 µs ± 202 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n",
      "number of features: 100\n",
      "1.85 ms ± 405 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n",
      " ________________________________________\n",
      "|algorithm| my_own\n",
      "|_________|______________________________\n",
      "number of features: 10\n",
      "101 µs ± 26 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n",
      "----------\n",
      "number of features: 20\n",
      "347 µs ± 73.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n",
      "number of features: 100\n",
      "1.21 ms ± 337 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "def get_random_features(size, number_of_features):\n",
    "    return np.sort(np.random.choice(range(number_of_features),size=size, replace=False))\n",
    "    \n",
    "features_10  = get_random_features(10,  X.shape[1])\n",
    "features_20  = get_random_features(20,  X.shape[1])\n",
    "features_100 = get_random_features(100, X.shape[1])\n",
    "\n",
    "n_neighbors = 5\n",
    "algorithms = ['kd_tree', 'ball_tree', 'brute', 'my_own']\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    print(' ________________________________________')\n",
    "    print('|algorithm|', algorithm)\n",
    "    print('|_________|______________________________')\n",
    "    model = BatchedKNNClassifier(n_neighbors=n_neighbors, algorithm=algorithm)\n",
    "    for number_of_features in [10, 20, 100]:\n",
    "        print('number of features:', number_of_features)\n",
    "        features = eval('features_%d' % number_of_features)\n",
    "        model.fit(X_train[features])\n",
    "        X_test_ = X_test[features]\n",
    "        %timeit model.kneighbors(X_test_, return_distance=True)\n",
    "        print('----------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Приведите график / таблицу с результатами вашего эксперимента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              | kd_tree | ball_tree | brute | my_own |\n",
    "|--------------|---------|-----------|-------|--------|\n",
    "| 10 features  | 0.955   | 0.726     | 0.563 | 0.208  |\n",
    "| 20 features  | 1.49    | 1.3       | 0.716 | 0.509  |\n",
    "| 100 features | 15.9    | 13.6      | 2.64  | 2.31   |\n",
    "\n",
    "Замечание. Время в миллисекундах (ms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответьте на следующие вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Какой алгоритм сработал быстрее всего для каждого из размера подвыборок? Ожидали ли вы такие результаты до проведения эксперимента?\n",
    "\n",
    "   для 10 признаков: my_own\\\n",
    "   для 20 признвков: my_own\\\n",
    "   для 100 признаков: my_own\n",
    "   \n",
    "   Результат был ожидаем, так как при малом числе признаков обычно более простые алгоритмы работают лучше. Более хитрые алгоритмы дают выигрыш при большом чсиле признаков."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Приведите теоретическую сложность каждого из алгоритмов поиска. Согласуется ли время работы алгоритмов на практике с их теоретической вычислительной сложностью? Как вы думаете, почему?\n",
    "    \n",
    "   kd_tree:\\\n",
    "   ball_tree:\\\n",
    "   brute: $O(n_{test}\\cdot n_{train})$\\\n",
    "   my_own:\\\n",
    "   \n",
    "   Время работы алгоритмов на практике не согласуется с их теоретической вычислительной сложностью, потому что $n$ не достаточно велико.\n",
    "   \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Какой алгоритм исходя из результатов эксперимента следует использовать в дальнейшем? Выберите алгоритм поиска соседей, который вы будете использовать во всех экспериментах ниже. \n",
    "\n",
    "    В пределах 700 признаков $brute$ растёт медленнее, и при 784 признаках будет работать быстрее других алгоритмов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Исследование зависимости точности алгоритма на кросс-валидации (4 балла)\n",
    "\n",
    "\n",
    "Оцените по кросс-валидации с 3 фолдами точность (долю правильно предсказанных ответов) алгоритма k ближайших соседей в зависимости от следующих факторов:\n",
    "* количество соседей k от 1 до 10\n",
    "* используется евклидова или косинусная метрика"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = 'brute'\n",
    "metrics =['euclidean', 'cosine']\n",
    "\n",
    "cv = KFold(n_splits=3)\n",
    "cv_res = {}\n",
    "for metric in metrics:\n",
    "    cv_res[metric] = knn_cross_val_score(X, y, range(1, 11), 'accuracy', cv=cv, algorithm=algorithm, metric=metric)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Нарисуйте график зависимости точности от количества соседей по каждой метрике"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "euclidean_accuracy = [cv_res['euclidean'][k].mean() for k in sorted(cv_res['euclidean'])]\n",
    "cosine_accuracy = [cv_res['cosine'][k].mean() for k in sorted(cv_res['cosine'])]\n",
    "best_unweighted_model_accuracy = max(cosine_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Точность невзвешенного алгоритма')\n",
    "plt.grid()\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('accuracy')\n",
    "plt.plot(range(1, 11), cosine_accuracy, color='r', label='cosine')\n",
    "plt.plot(range(1, 11), euclidean_accuracy, color='b', label='euclidean')\n",
    "plt.xticks(range(1,11))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответьте на следующие вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. По результатам эксперимента, какие гиперпараметры вы считаете наиболее оптимальными? Обоснуйте свой выбор (например, если у вас несколько наборов параметров с высоким качеством, обоснуйте как вы выберите среди этих наборов один).\n",
    "\n",
    "   Согласно графику, наиболее оптимальными являются параметры: metric = 'cosine', n_neighbors = 3\n",
    "\n",
    "\n",
    "2. Какая метрика лучше себя показала в экспериментах? Можете ли вы объяснить, почему?\n",
    "\n",
    "    Лучше метрика 'cosine', так как в этой задаче важнее \"сонаправленность\" векторов, а не евклидово расстояние между ними. Допустим, есть два сонаправленных вектора разной длины. Это означает, что рисунки, кодируемые этими векторами идентичны по форме, но различна интенсивность пикселей. Разумно считать расстояние между этими векторами равным нулю (что и получается при использовании косинусной метрики. А при использовании евклидовой метрики расстояние между ними будет больше нуля).\n",
    "    \n",
    "   \n",
    "2. Есть ли на графике зависимости точности от количество соседей \"выбросы\", резкие падения/повышения качества для одного значения k по сравнению с соседними? Если да, предположите причину появления этих выбросов.\n",
    "\n",
    "    Выбросы есть: $1 \\rightarrow 2,\\ 2 \\rightarrow 3$.\\\n",
    "    При переходе от одного к двум соседям точность резко падает потому, что есть пары похожих цифр ($3$ и $9$, $8$ и $9$, $4$ и $1$ и т.д.), поэтому при двух соседях возрастает неопределённость в выборе. Например, для $9$ двумя ближайшими соседями могут оказаться $9$ и $3$.\\\n",
    "    При переходе от двух к трём соседям точность резко возрастает потому, что:\\\n",
    "    1) видимо, нивелируется проблема, описанная для случая двух соседей (из-за этого происходит резкий скачок ввех);\\\n",
    "    2) увеличение точности за счёт увеличения числа соседей (из-за это точность чуть выше, чем при $n=1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Исследование зависимости точности взвешенного алгоритма на кросс-валидации (4 балла)\n",
    "\n",
    "По результатам предыдущего эксперимента выберите метрику, которую вы будете использовать в этом эксперименте.\n",
    "\n",
    "Оцените по кросс-валидации с 3 фолдами точность (долю правильно предсказанных ответов) взвешенного алгоритма k ближайших соседей в зависимости от количество соседей k (от 1 до 10).\n",
    "\n",
    "Голос объекта положите равным `1 / (distance + eps)`, где `eps` = `1e-5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 'cosine'\n",
    "weights = 'distance'\n",
    "batch_size = 69\n",
    "\n",
    "cv_res_weights = knn_cross_val_score(X, y, range(1, 11), 'accuracy', cv=cv, algorithm=algorithm, metric=metric, weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [cv_res_weights[acc].mean() for acc in sorted(cv_res_weights)]\n",
    "best_weighted_model_accuracy = max(accuracy)\n",
    "print('Точность лучшей невзвешенной модели:', best_unweighted_model_accuracy)\n",
    "print('Точность лучшей взвешенной модели:  ', best_weighted_model_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Нарисуйте график зависимости точности от количества соседей "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = [cv_res_weights[acc].mean() for acc in sorted(cv_res_weights)]\n",
    "plt.title('Точность взвешенного алгоритма')\n",
    "plt.grid()\n",
    "plt.xlabel('n')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xticks(range(1,11))\n",
    "plt.plot(range(1,11), accuracy, color='b', label='lolo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ответьте на следующие вопросы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. По результатам эксперимента, какие гиперпараметры вы считаете наиболее оптимальными? Обоснуйте свой выбор.\n",
    "   \n",
    "   Из графика следует, что оптимальным числом соседей явяется $n_{neighbors} = 4$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Сравните результаты взвешенного алгоритма с невзвешенным. Объясните разницу/отсутствие разницы в результатах.\n",
    "\n",
    "   Точность лучшей невзвешенной модели: 0.9730999806015425.\\\n",
    "   Точность лучшей взвешенной модели:   0.9740999801937931.\\\n",
    "   Взвешенный алгоритм лучше, потому что разумно, чтобы более близкие соседи имели больший вес."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Применение алгоритма и интерпретация ошибок (3 балла)\n",
    "\n",
    "1. Примените лучший алгоритм к исходной обучающей и тестовой выборке и посчитайте точность классификации. Сравните с точностью по кросс-валидации. Опишите ваши результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BatchedKNNClassifier(n_neighbors=4, metric='cosine', weights='distance', batch_size=2000)\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "#score = accuracy_score(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = accuracy_score(y, y_pred)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность получилась выше, чем при проверке по кросс-валидации, так как обучение происходило в том числе на предсказываемых объектах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Постройте и проанализируйте матрицу ошибок (confusion matrix), используйте функцию `sklearn.metrics.confusion_matrix`. Визуализируйте несколько объектов из тестовой выборки, на которых были допущены ошибки. Проанализируйте и укажите их общие черты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ваше описание здесь*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус 1. Размножение обучающей выборки (3 балла)\n",
    "\n",
    "Размножьте обучающую выборку с помощью поворотов, смещений, применений гауссовского фильтра и морфологических операций. Разрешается использовать библиотеки для работы с изображениями. Подобрать по кросс-валидации с 3 фолдами параметры преобразований. Рассмотреть следующие параметры для преобразований и их комбинации:\n",
    "1. Величина поворота: 5, 10, 15 (в каждую из двух сторон)\n",
    "2. Величина смещения: 1, 2, 3 пикселя (по каждой из двух размерностей)\n",
    "3. Дисперсия фильтра Гаусса: 0.5, 1, 1.5\n",
    "4. Морфологические операции: эрозия, дилатация, открытие, закрытие с ядром 2\n",
    "\n",
    "Проанализируйте, как изменилась матрица ошибок, какие ошибки алгоритма помогает исправить каждое\n",
    "преобразование.\n",
    "\n",
    "**Замечание.** Не обязательно хранить все обучающие выборки в процессе эксперимента. Достаточно вычислить ближайших соседей по каждой из выборок, а затем выбрать из них ближайших соседей.\n",
    "\n",
    "**Замечание по дизайну эксперимента**. В этой части вам предлагается самим выбрать дизайн эксперимента. Перебор всевоможных комбинаций преобразований может быть затруднительным, в то время как жадный выбор преобразований уже даст улучшение в качестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус 2. Размножение тестовой выборки (2 балла)\n",
    "\n",
    "Реализуйте предложенный на семинаре алгоритм, основанный на преобразовании объектов тестовой выборки.\n",
    "Проверьте то же самое множество параметров, что и в предыдущем пункте.\n",
    "\n",
    "Проанализируйте как изменилась матрица ошибок, какие ошибки алгоритма помогает исправить каждое\n",
    "преобразование."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## your code here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Бонус 3. Сравнение подходов (1 балл)\n",
    "\n",
    "Если вы реализовали оба подхода, сравните их между собой.\n",
    "\n",
    "1. Какой подход даёт больший выигрыш в качестве и почему?\n",
    "\n",
    "    *ваш ответ*\n",
    "    \n",
    "\n",
    "2. Есть ли какие-то преимущества у худшего по качеству подхода по сравнению с лучшим?\n",
    "\n",
    "    *ваш ответ*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
